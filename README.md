### Bayes Rule
<img src="https://user-images.githubusercontent.com/31917400/34920230-5115b6b6-f967-11e7-9493-5f6662f1ce70.JPG" width="400" height="500" />
We know the Bayes rule. How does it relate to machine learning? 

### Introduction
 - Frequentists' probability that doesn’t depend on one’s beliefs: refers to **past events**..   
 - Bayesians' probability as a measure of beliefs: refers to **future events**.. 

As Bayesians, we start with a belief, called a prior. Then we obtain some data and use it to update our belief. The outcome is called a posterior. Should we obtain even more data, the old posterior becomes a new prior and the cycle repeats.
<img src="https://user-images.githubusercontent.com/31917400/64063569-a9533100-cbed-11e9-89d6-a8cc6203b886.jpg"/>





































































































